runtime: &runtime
  seed: 42

  use_cond: true
  filter_by_cond: true

  num_observation: 1  # number of input reference images
  visual_guidance: true  # use additional visual conditions
  control_keys: ['depth', 'label']
  
dataset:
  <<: *runtime

  load_actions: true
  load_tensors: true  # load pre-encoded latents instead of raw data
  load_video: false
  load_condGT: false  # will load conditions from reconstructions

  slice_frame: true  # if False, will use the entire video
  use_3dvae: true
  num_samples: -1
  no_normalize: false

transformer:
  <<: *runtime
  pretrained_model_name_or_path: THUDM/CogVideoX-2b
  transformer_model_name_or_path: outputs/orv_bridge_traj-image-condfull_480-320_finetune_2b_20k/checkpoint
  # transformer_model_name_or_path: outputs/orv_rt1_traj-image-condfull_480-320_finetune_2b_20k/checkpoint

evaluation:
  <<: *runtime
  output_dir: null  # will use the name of checkpoint

  mode: traj-image-depth    # ['traj-image', 'traj-image-depth', 'traj-image-label', 'traj-image-depth-label']

  batch_size: 4